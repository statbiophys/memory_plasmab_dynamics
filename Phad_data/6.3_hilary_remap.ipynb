{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f395bec-3a34-49c7-b36d-4b47b5e62b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, \"../func_py/\")\n",
    "import data_utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2d9d6b-3356-4444-9c22-d88a4120c9c6",
   "metadata": {},
   "source": [
    "### Here we map back the families found by hilary at the patient level to the different samples of each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2f8efc-c31f-429c-875d-183e9bce4226",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('metadata/metadata.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "287ab6db-045c-4f0e-800a-1465c02cb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = 2\n",
    "\n",
    "famh_sample = 'pat'+str(pat)+'_hilary_heavy'\n",
    "f_famh = pd.read_csv('lineages/hilary_out/inferred_full_method_'+famh_sample+'.tsv', sep='\\t', index_col='sequence_id')\n",
    "f_famh.index = f_famh.index.str.split('-').str[0] + '-' + f_famh.index.str.split('-').str[1]\n",
    "\n",
    "famp_sample = 'pat'+str(pat)+'_hilary_pairs_'\n",
    "f_famph = pd.read_csv('lineages/hilary_out/inferred_full_method_'+famp_sample+'h.tsv', sep='\\t', index_col='old_seq_id')\n",
    "f_famph.index = f_famph.index.str.split('-').str[0] + '-' + f_famph.index.str.split('-').str[1]\n",
    "f_fampl = pd.read_csv('lineages/hilary_out/inferred_full_method_'+famp_sample+'l.tsv', sep='\\t', index_col='old_seq_id')\n",
    "f_fampl.index = f_fampl.index.str.split('-').str[0] + '-' + f_fampl.index.str.split('-').str[1]\n",
    "famp_map = pd.concat((f_famph.family, f_fampl.family))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03721bf6-483d-40b8-ad98-553be65e7bf7",
   "metadata": {},
   "source": [
    "## Mapping families from hilary frame to sample-frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46993a0a-24af-462d-812e-04e623549104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pat2_t1_mc\n",
      "check percentage assigned heavy families 99.96082949308756\n",
      "check percentage assigned pair families 99.95696703675016\n",
      "\n",
      "pat2_t2_mc\n",
      "check percentage assigned heavy families 99.96275720803203\n",
      "check percentage assigned pair families 99.96262660238442\n",
      "\n",
      "pat2_t3_mc\n",
      "check percentage assigned heavy families 99.98562633255875\n",
      "check percentage assigned pair families 99.98656556006688\n",
      "\n",
      "pat2_t1_pc\n",
      "check percentage assigned heavy families 100.0\n",
      "check percentage assigned pair families 100.0\n",
      "\n",
      "pat2_t2_pc\n",
      "check percentage assigned heavy families 100.0\n",
      "check percentage assigned pair families 100.0\n",
      "\n",
      "pat2_t3_pc\n",
      "check percentage assigned heavy families 99.97851079832384\n",
      "check percentage assigned pair families 99.9881390107935\n",
      "\n",
      "pat2_t4_pc\n",
      "check percentage assigned heavy families 100.0\n",
      "check percentage assigned pair families 100.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for samp, row in metadata[metadata.patient == pat].iterrows():\n",
    "    f = pd.read_csv('sequences/'+samp+'.tsv', sep='\\t', index_col=0, low_memory=False)\n",
    "    print(samp)\n",
    "    \n",
    "    # Mapping families of heavy sequences\n",
    "    f['familiy_heavy'] = f.pat_heavy_id.map(f_famh.family)\n",
    "    fh = f[f.chain == 'H']\n",
    "    print('check percentage assigned heavy families', np.sum(fh.familiy_heavy.notna()) / len(fh) * 100)\n",
    "    \n",
    "    # Mapping families of paired sequences\n",
    "    f['familiy_pairs'] = f.pat_pairs_id.map(famp_map)\n",
    "    fp = f[f.paired_seq.notna()]\n",
    "    print('check percentage assigned pair families', np.sum(fp.familiy_pairs.notna()) / len(fp) * 100)\n",
    "    f.to_csv('sequences/'+samp+'.tsv', sep='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79558e76-4b07-483a-a2c4-e85412af898b",
   "metadata": {},
   "source": [
    "## Mapping families from sample frames to replicate frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "401a2f3d-4509-4d18-8e81-61bfa420bf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pat2_t1_mc\n",
      "check percentage assigned heavy families 99.95506122907538\n",
      "check percentage assigned pair families 99.94531784005468\n",
      "check percentage assigned heavy families 99.98765889176849\n",
      "check percentage assigned pair families 99.98482779547868\n",
      "check percentage assigned heavy families 99.94984954864594\n",
      "check percentage assigned pair families 99.95323460639128\n",
      "check percentage assigned heavy families 99.94445678738059\n",
      "check percentage assigned pair families 99.94563740146779\n",
      "check percentage assigned heavy families 99.97064866451424\n",
      "check percentage assigned pair families 99.96237772761475\n",
      "pat2_t2_mc\n",
      "check percentage assigned heavy families 99.94044073853485\n",
      "check percentage assigned pair families 99.94679907785068\n",
      "check percentage assigned heavy families 99.98514777959305\n",
      "check percentage assigned pair families 99.98222222222222\n",
      "check percentage assigned heavy families 99.96305191206355\n",
      "check percentage assigned pair families 99.95513683266039\n",
      "check percentage assigned heavy families 99.94114184814596\n",
      "check percentage assigned pair families 99.94726665494814\n",
      "check percentage assigned heavy families 99.98598261844688\n",
      "check percentage assigned pair families 99.9830852503383\n",
      "pat2_t3_mc\n",
      "check percentage assigned heavy families 99.98806112702961\n",
      "check percentage assigned pair families 99.98543123543124\n",
      "check percentage assigned heavy families 99.98728059018062\n",
      "check percentage assigned pair families 100.0\n",
      "check percentage assigned heavy families 100.0\n",
      "check percentage assigned pair families 100.0\n",
      "check percentage assigned heavy families 99.96608636671942\n",
      "check percentage assigned pair families 99.9578947368421\n",
      "check percentage assigned heavy families 99.98834498834499\n",
      "check percentage assigned pair families 99.99283256880734\n",
      "pat2_t1_pc\n",
      "check percentage assigned heavy families 100.0\n",
      "check percentage assigned pair families 100.0\n",
      "pat2_t2_pc\n",
      "check percentage assigned heavy families 100.0\n",
      "check percentage assigned pair families 100.0\n",
      "check percentage assigned heavy families 100.0\n",
      "check percentage assigned pair families 100.0\n",
      "check percentage assigned heavy families 100.0\n",
      "check percentage assigned pair families 100.0\n",
      "pat2_t3_pc\n",
      "check percentage assigned heavy families 99.98013113451222\n",
      "check percentage assigned pair families 99.97800747745767\n",
      "check percentage assigned heavy families 99.9781325169473\n",
      "check percentage assigned pair families 100.0\n",
      "pat2_t4_pc\n",
      "check percentage assigned heavy families 100.0\n",
      "check percentage assigned pair families 100.0\n",
      "check percentage assigned heavy families 100.0\n",
      "check percentage assigned pair families 100.0\n"
     ]
    }
   ],
   "source": [
    "for samp, row in metadata[metadata.patient == pat].iterrows():\n",
    "#for samp in ['pat1_t2_mc']:\n",
    "    \n",
    "    f_samp = pd.read_csv('sequences/'+samp+'.tsv', sep='\\t', index_col=0, low_memory=False)\n",
    "    print(samp)\n",
    "    \n",
    "    for r in range(metadata.loc[samp, 'repl_count']):\n",
    "        \n",
    "        f_r = pd.read_csv('sequences/replicates/'+samp+'_r'+str(r+1)+'.tsv', sep='\\t', index_col=0, low_memory=False)\n",
    "        f_r['familiy_heavy'] = f_r.sample_id.map(f_samp.familiy_heavy)\n",
    "        fh = f_r[f_r.chain == 'H']\n",
    "        print('check percentage assigned heavy families', np.sum(fh.familiy_heavy.notna()) / len(fh) * 100)\n",
    "        \n",
    "        f_r['familiy_pairs'] = f_r.sample_id.map(f_samp.familiy_pairs)\n",
    "        fp = f_r[f_r.paired_seq.notna()]\n",
    "        print('check percentage assigned pair families', np.sum(fp.familiy_pairs.notna()) / len(fp) * 100)\n",
    "    \n",
    "        f_r.to_csv('sequences/replicates/'+samp+'_r'+str(r+1)+'.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74ce36-b92e-490f-878a-f89528514c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
