{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf94db23-ceef-47b1-8d0e-315d18dfbbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../func_py/\")\n",
    "import infer_noise as infn\n",
    "import data_utils as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce8aa68-968d-44f5-b6dc-d6f1b042cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('metadata/metadata.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625944da-f8f1-412c-ad85-a823b414f6ea",
   "metadata": {},
   "source": [
    "### Leraning the three noise models for all the memory or plasmablast samples\n",
    "\n",
    "The learned parameters are saved in the `inference/noise` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0fa483-9048-4ac4-8f70-0e5711cb32c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = metadata[metadata.cell == 'm'] # change 'm' to 'p' for the plasmablast processing\n",
    "samples = aux[aux.repl_count > 1].index\n",
    "for sample in samples:\n",
    "    \n",
    "    # Discarding the samples not used in the analysis\n",
    "    if sample == 'pat1_t4_pc' or sample == 'pat1_t1_pc':\n",
    "        continue\n",
    "        \n",
    "    print(sample)\n",
    "    n_uniq, n_counts = dt.import_sample_counts(sample, metadata.loc[sample].repl_count)\n",
    "    \n",
    "    # Poisson\n",
    "    infer = infn.infer_noise_poiss(n_uniq, n_counts, False, n_points=10000)\n",
    "    infer.run(x0=(2.3, -5.5), bounds=((2, 2.7), (-7, -4.5)))\n",
    "    infer.compute_errors()\n",
    "    infer.write_on_file('inference/noise/', sample+'_'+infer.name+'.txt')\n",
    "    print(infer.result.x)\n",
    "    \n",
    "    # Neg bin beta = 1\n",
    "    infer = infn.infer_noise_negbin(n_uniq, n_counts, False, False, n_points=10000, n_threads=5)\n",
    "    infer.run(x0=(2.3, -5.5, 0.1), bounds=((2, 2.7), (-7, -4.5), (0.001, 2)))\n",
    "    infer.compute_errors()\n",
    "    infer.write_on_file('inference/noise/', sample+'_'+infer.name+'.txt')\n",
    "    print(infer.result.x)\n",
    "    \n",
    "    # Neg bin free beta\n",
    "    infer = infn.infer_noise_negbin(n_uniq, n_counts, True, False, n_points=10000, n_threads=5)\n",
    "    infer.run(x0=(2.3, -5.5, 0.1, 1), bounds=((2, 2.7), (-7, -4.5), (0.001, 2), (0.3, 3)))\n",
    "    infer.compute_errors()\n",
    "    infer.write_on_file('inference/noise/', sample+'_'+infer.name+'.txt')\n",
    "    print(infer.result.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425248e7-72b7-4781-ab6f-4bcc3a2849f6",
   "metadata": {},
   "source": [
    "### Re-learning by fine-tuning the hyperparameters the samples that didn't find an error\n",
    "(that possibly did not converge well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd7983-27a9-42c1-b80e-6e3f0191b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"pat1_t2_pc\"\n",
    "n_uniq, n_counts = dt.import_sample_counts(sample, metadata.loc[sample].repl_count)\n",
    "infer = infn.infer_noise_negbin(n_uniq, n_counts, False, False, n_points=10000, verbose=True)\n",
    "infer.ftol = 10**(-5)\n",
    "infer.eps_SLSQP = 10**(-2)\n",
    "infer.run(x0=(2.5, -6, 0.1), bounds=((2, 3), (-7, -4), (0.001, 1)))\n",
    "infer.compute_errors()\n",
    "print(infer.result)\n",
    "print(infer.errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
